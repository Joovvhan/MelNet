{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayedRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden):\n",
    "        super(DelayedRNN, self).__init__()\n",
    "\n",
    "        self.t_delay_RNN_x = nn.GRU(input_size=num_hidden, hidden_size=num_hidden, batch_first=True)\n",
    "        self.t_delay_RNN_y = nn.GRU(input_size=num_hidden, hidden_size=num_hidden, batch_first=True)\n",
    "        self.t_delay_RNN_z = nn.GRU(input_size=num_hidden, hidden_size=num_hidden, batch_first=True)\n",
    "\n",
    "        self.W_t = nn.Linear(3 * num_hidden, num_hidden)\n",
    "\n",
    "        self.c_RNN = nn.GRU(input_size=num_hidden, hidden_size=num_hidden, batch_first=True)\n",
    "\n",
    "        self.W_c = nn.Linear(num_hidden, num_hidden)\n",
    "\n",
    "        self.f_delay_RNN = nn.GRU(input_size=num_hidden, hidden_size=num_hidden, batch_first=True)\n",
    "\n",
    "        self.W_f = nn.Linear(num_hidden, num_hidden)\n",
    "\n",
    "    def forward(self, input_h_t, input_h_f, input_h_c):\n",
    "\n",
    "        h_t_x = Variable(torch.zeros(input_h_t.shape))\n",
    "        h_t_y = Variable(torch.zeros(input_h_t.shape))\n",
    "        h_t_z = Variable(torch.zeros(input_h_t.shape))\n",
    "\n",
    "        for i in range(input_h_t.shape[2]):\n",
    "            h_t_x_slice, _ = self.t_delay_RNN_x(input_h_t[:, :, i, :])\n",
    "            h_t_x[:, :, i, :] = h_t_x_slice\n",
    "\n",
    "        reverse_index = np.arange(input_h_t.shape[2] - 1, -1, -1)\n",
    "        for i in range(input_h_t.shape[1]):\n",
    "            h_t_y_slice, _ = self.t_delay_RNN_y(input_h_t[:, i, :, :])\n",
    "            h_t_z_slice, _ = self.t_delay_RNN_z(input_h_t[:, i, reverse_index, :])\n",
    "            h_t_y[:, i, :, :] = h_t_y_slice\n",
    "            h_t_z[:, i, :, :] = h_t_z_slice[:, reverse_index, :]\n",
    "\n",
    "        h_t_concat = torch.cat([h_t_x, h_t_y, h_t_z], 3)\n",
    "\n",
    "        h_t_w = self.W_t(h_t_concat)\n",
    "\n",
    "        output_h_t = torch.add(input_h_t, h_t_w)\n",
    "\n",
    "        h_c_rnn, _ = self.c_RNN(input_h_c)\n",
    "        h_c_w = self.W_c(h_c_rnn)\n",
    "        output_h_c = torch.add(input_h_c, h_c_w)\n",
    "\n",
    "        h_c_expand = output_h_c.view(output_h_c.shape[0], output_h_c.shape[1], 1, output_h_c.shape[2]).repeat(1, 1, 32, 1)\n",
    "        h_f_sum = torch.add(torch.add(input_h_f, output_h_t), h_c_expand)\n",
    "\n",
    "        h_f_ = Variable(torch.zeros(input_h_f.shape))\n",
    "\n",
    "        for i in range(h_f_sum.shape[1]):\n",
    "            h_f_slice, _ = self.f_delay_RNN(h_f_sum[:, i, :, :])\n",
    "            h_f_[:, i, :, :] = h_f_slice\n",
    "\n",
    "        h_f_w = self.W_f(h_f_)\n",
    "\n",
    "        output_h_f = torch.add(input_h_f, h_f_w)\n",
    "\n",
    "        return output_h_t, output_h_f, output_h_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_hidden, num_layer, K):\n",
    "        super(MelNet, self).__init__()\n",
    "        \n",
    "        self.W_t_0 = nn.Linear(1, num_hidden)\n",
    "        self.W_f_0 = nn.Linear(1, num_hidden)\n",
    "        self.W_c_0 = nn.Linear(32, num_hidden)\n",
    "        \n",
    "        self.module_list = nn.ModuleList([DelayedRNN(512) for i in range(num_layer)])\n",
    "\n",
    "        self.W_theta = nn.Linear(num_hidden, 3 * K)\n",
    "        self.pi_softmax = nn.Softmax(dim=3)\n",
    "        self.K = K\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        h_t = self.W_t_0(input_tensor)\n",
    "        h_f = self.W_f_0(input_tensor)\n",
    "#         h_c = self.W_c_0(input_tensor[:, :, :, 0])\n",
    "        h_c = self.W_c_0(input_tensor[:, :, :, 0])\n",
    "        \n",
    "#         print('h_t: {}\\nh_f: {}\\nh_c: {}'.format(h_t.shape, h_f.shape, h_c.shape))\n",
    "        \n",
    "        for layer in self.module_list:\n",
    "            h_t, h_f, h_c = layer(h_t, h_f, h_c)\n",
    "            \n",
    "        theta_hat = self.W_theta(h_f)\n",
    "        \n",
    "        mu = theta_hat[:, :, :, :K]\n",
    "        std = torch.exp(theta_hat[:, :, :, K:2*K])\n",
    "        pi = self.pi_softmax(theta_hat[:, :, :, 2*K:])\n",
    "        \n",
    "#         loss = torch.tensor([0])\n",
    "        \n",
    "#         for batch in range(mu.shape[0]):\n",
    "#             for i in range(mu.shape[1]):\n",
    "#                 for j in range(mu.shape[2]):\n",
    "#                     prob = 0\n",
    "#                     for k in range(self.K):\n",
    "#                         prob += pi[batch, i, j, k] * torch.exp(torch.distributions.normal.Normal(mu[batch, i, j, k], std[batch, i, j, k]).log_prob(input_tensor[batch, i, j, 0]))\n",
    "\n",
    "#                     loss = torch.add(loss, -torch.log(prob))\n",
    "\n",
    "        dist = (1.0 / np.sqrt(2*np.pi) * torch.exp(-0.5 * ((input_tensor - mu) / std)**2) / std)\n",
    "        prob = pi * dist\n",
    "        loss = - torch.log(torch.sum(prob, dim=3))\n",
    "        mean_loss = torch.mean(loss)\n",
    "        \n",
    "        return mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MelNet(512, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of MelNet(\n",
       "  (W_t_0): Linear(in_features=1, out_features=512, bias=True)\n",
       "  (W_f_0): Linear(in_features=1, out_features=512, bias=True)\n",
       "  (W_c_0): Linear(in_features=32, out_features=512, bias=True)\n",
       "  (module_list): ModuleList(\n",
       "    (0): DelayedRNN(\n",
       "      (t_delay_RNN_x): GRU(512, 512, batch_first=True)\n",
       "      (t_delay_RNN_y): GRU(512, 512, batch_first=True)\n",
       "      (t_delay_RNN_z): GRU(512, 512, batch_first=True)\n",
       "      (W_t): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (c_RNN): GRU(512, 512, batch_first=True)\n",
       "      (W_c): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (f_delay_RNN): GRU(512, 512, batch_first=True)\n",
       "      (W_f): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): DelayedRNN(\n",
       "      (t_delay_RNN_x): GRU(512, 512, batch_first=True)\n",
       "      (t_delay_RNN_y): GRU(512, 512, batch_first=True)\n",
       "      (t_delay_RNN_z): GRU(512, 512, batch_first=True)\n",
       "      (W_t): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (c_RNN): GRU(512, 512, batch_first=True)\n",
       "      (W_c): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (f_delay_RNN): GRU(512, 512, batch_first=True)\n",
       "      (W_f): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (2): DelayedRNN(\n",
       "      (t_delay_RNN_x): GRU(512, 512, batch_first=True)\n",
       "      (t_delay_RNN_y): GRU(512, 512, batch_first=True)\n",
       "      (t_delay_RNN_z): GRU(512, 512, batch_first=True)\n",
       "      (W_t): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (c_RNN): GRU(512, 512, batch_first=True)\n",
       "      (W_c): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (f_delay_RNN): GRU(512, 512, batch_first=True)\n",
       "      (W_f): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (W_theta): Linear(in_features=512, out_features=30, bias=True)\n",
       "  (pi_softmax): Softmax(dim=3)\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsc = 6 * 256\n",
    "hop = 256\n",
    "nov = nsc - hop\n",
    "n_mels = 256\n",
    "fs = 44100/2\n",
    "num_hidden = 512\n",
    "K = 10\n",
    "eps = 1e-8\n",
    "db_ref = 160\n",
    "\n",
    "mel_filters = librosa.filters.mel(sr=fs, n_fft=nsc, n_mels=n_mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = \"D:/korean-single-speaker-speech-dataset/transcript.v.1.2.txt\"\n",
    "with open(meta_path, encoding='utf-8') as f:\n",
    "    metadata = np.array([line.strip().split('|') for line in f])\n",
    "    \n",
    "wave_name_list = []\n",
    "\n",
    "for data in metadata:\n",
    "    wave_name_list.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5070b82048d04e338f4dd980deb85905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12853), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"D:/korean-single-speaker-speech-dataset/kss\"\n",
    "\n",
    "mel_path_list = list()\n",
    "mel_shape_list = list()\n",
    "\n",
    "for i, wav_name in enumerate(tqdm(wave_name_list)):\n",
    "    \n",
    "    npy_name = wav_name.replace('.wav', '.npy')\n",
    "    wav_path = os.path.join(data_folder, wav_name)  \n",
    "    save_path = os.path.join(data_folder + '/MelNet', npy_name)\n",
    "    mel_path_list.append(save_path)\n",
    "    \n",
    "    if not os.path.isfile(save_path):\n",
    "        y, sr = librosa.core.load(wav_path)\n",
    "        f, t, Zxx = sp.signal.stft(y, fs=sr, nperseg=nsc, noverlap=nov)\n",
    "        Sxx = np.abs(Zxx)\n",
    "        Sxx = np.maximum(Sxx, eps)\n",
    "\n",
    "        mel_filters = librosa.filters.mel(sr=fs, n_fft=nsc, n_mels=n_mels)\n",
    "        mel_specgram = np.matmul(mel_filters, Sxx)\n",
    "\n",
    "        log_mel_specgram = 20 * np.log10(np.maximum(mel_specgram, eps))\n",
    "        norm_log_mel_specgram = (log_mel_specgram + db_ref) / db_ref\n",
    "        \n",
    "        mel_shape_list.append(norm_log_mel_specgram.shape)\n",
    "\n",
    "        np.save(save_path, norm_log_mel_specgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"D:/korean-single-speaker-speech-dataset/kss\"\n",
    "\n",
    "# file_list = glob.glob(data_dir + '/*')\n",
    "# y, fs = librosa.core.load(file_list[0])\n",
    "\n",
    "# f, t, Sxx = scipy.signal.stft(y, fs=fs, window='hann', nperseg=nsc, noverlap=nov)\n",
    "# # Sxx = Sxx[1:, :]\n",
    "# Zxx = np.abs(Sxx)\n",
    "# log_spectrogram = 20 * np.log10(np.maximum(Zxx, 1e-8))\n",
    "# log_spectrogram_norm = (log_spectrogram + 160) / 160\n",
    "\n",
    "# mel_spectrogram = np.matmul(mel_filters, Zxx)\n",
    "# log_mel_spectrogram = 20 * np.log10(np.maximum(mel_spectrogram, 1e-8))\n",
    "# mel_input = (log_mel_spectrogram + 160) / 160\n",
    "\n",
    "# Tier6 = mel_input[::2, :]\n",
    "# Tier6_not = mel_input[1::2, :]\n",
    "\n",
    "# Tier5 = Tier6_not[:, ::2]\n",
    "# Tier5_not = Tier6_not[:, 1::2]\n",
    "\n",
    "# Tier4 = Tier5_not[::2, :]\n",
    "# Tier4_not = Tier5_not[1::2, :]\n",
    "\n",
    "# Tier3 = Tier4_not[:, ::2]\n",
    "# Tier3_not = Tier4_not[:, 1::2]\n",
    "\n",
    "# Tier2 = Tier3_not[::2, :]\n",
    "# Tier1 = Tier3_not[1::2, :]\n",
    "\n",
    "# Tiers = [Tier1, Tier2, Tier3, Tier4, Tier5, Tier6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tier1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3bbb237acd8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTier1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tier1' is not defined"
     ]
    }
   ],
   "source": [
    "# tensor = torch.tensor(Tier1.T)\n",
    "# input_tensor = tensor.view([1, tensor.shape[0], tensor.shape[1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tier(batched_tensor):\n",
    "    Tier6 = batched_tensor[:, :, ::2]\n",
    "    Tier6_not = batched_tensor[:, :, 1::2]\n",
    "\n",
    "    Tier5 = Tier6_not[:, ::2, :]\n",
    "    Tier5_not = Tier6_not[:, 1::2, :]\n",
    "\n",
    "    Tier4 = Tier5_not[:, :, ::2]\n",
    "    Tier4_not = Tier5_not[:, :, 1::2]\n",
    "\n",
    "    Tier3 = Tier4_not[:, ::2, :]\n",
    "    Tier3_not = Tier4_not[:, 1::2, :]\n",
    "\n",
    "    Tier2 = Tier3_not[:, :, ::2]\n",
    "    Tier1 = Tier3_not[:, :, 1::2]\n",
    "\n",
    "    Tiers = [Tier1, Tier2, Tier3, Tier4, Tier5, Tier6]\n",
    "    \n",
    "    return Tiers\n",
    "\n",
    "def find_next_multiple(num, target):\n",
    "    ans = num * np.int(np.ceil(target / num))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch_Loader():\n",
    "    def __init__(self, mel_path_list, batch_size):\n",
    "        super(Batch_Loader).__init__()\n",
    "        self.mel_path_list = mel_path_list\n",
    "        self.total_num_input = len(mel_path_list)\n",
    "        self.tensor_input_list = [None] * self.total_num_input\n",
    "        self.shuffle_step = 20\n",
    "        self.loading_sequence = None\n",
    "        self.end_flag = True\n",
    "        self.batch_size = batch_size\n",
    "        self.tensor_length_list = list()\n",
    "    \n",
    "    def load(self, i):\n",
    "        norm_log_mel_specgram = np.load(self.mel_path_list[i])\n",
    "        input_spectrogram = norm_log_mel_specgram.T\n",
    "        tensor_input = torch.tensor(input_spectrogram).view(1, input_spectrogram.shape[0], input_spectrogram.shape[1])\n",
    "        self.tensor_input_list[i] = tensor_input\n",
    "        \n",
    "    def get(self, i):\n",
    "        if type(self.tensor_input_list[i]) == type(None):\n",
    "            self.load(i)\n",
    "        return self.tensor_input_list[i]  \n",
    "    \n",
    "    def load_all(self):\n",
    "        for i in tqdm(range(len(self.mel_path_list))):\n",
    "            self.tensor_length_list.append(self.get(i).shape[1])\n",
    "        \n",
    "        self.tensor_length_list = np.asarray(self.tensor_length_list)\n",
    "    \n",
    "    def initialize_batch(self):\n",
    "        if len(self.tensor_length_list) == 0:\n",
    "            self.load_all()\n",
    "        loading_sequence = np.argsort(self.tensor_length_list)\n",
    "#       print(loading_sequence)\n",
    "#       print(type(loading_sequence))\n",
    "        bundle = np.stack([self.tensor_length_list[loading_sequence], loading_sequence])\n",
    "        \n",
    "        for seq_len in range(self.shuffle_step, np.max(self.tensor_length_list), self.shuffle_step):\n",
    "            idxs = np.where((bundle[0, :] > seq_len) & (bundle[0, :] <= seq_len + self.shuffle_step))[0]\n",
    "            idxs_origin = copy.deepcopy(idxs)\n",
    "            random.shuffle(idxs)\n",
    "            bundle[:, idxs_origin] = bundle[:, idxs]\n",
    "            \n",
    "        loading_sequence = bundle[1, :]\n",
    "        \n",
    "        self.loading_sequence = loading_sequence\n",
    "        self.current_loading_index = 0\n",
    "        self.end_flag = False\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def get_batch(self):\n",
    "        \n",
    "        tensor_list = list()\n",
    "        tensor_size_list = list()\n",
    "        \n",
    "        count = 0\n",
    "        max_seq_len = 0\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            \n",
    "            if self.current_loading_index >= self.total_num_input:\n",
    "                self.end_flag = True\n",
    "                break\n",
    "            \n",
    "            tensor = self.get(self.loading_sequence[self.current_loading_index])\n",
    "            tensor_list.append(tensor)\n",
    "            tensor_size_list.append(tensor.shape[1])\n",
    "             \n",
    "            if (tensor.shape[1] > max_seq_len):\n",
    "                max_seq_len = tensor.shape[1] \n",
    "            \n",
    "            self.current_loading_index += 1\n",
    "            count += 1\n",
    "            \n",
    "        batch_len = find_next_multiple(8, max_seq_len)\n",
    "            \n",
    "        batched_tensor = torch.zeros(count, batch_len, n_mels)\n",
    "        batched_loss_mask = torch.zeros(count, batch_len, n_mels)\n",
    "        \n",
    "        for order in range(count):\n",
    "            batched_tensor[order, :tensor_size_list[order], :] = tensor_list[order]\n",
    "            batched_loss_mask[order, :tensor_size_list[order], :] = torch.ones(tensor_list[order].shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return batched_tensor, batched_loss_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_loader = Batch_Loader(mel_path_list, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7507, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5077, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8073, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6928, grad_fn=<MeanBackward0>)\n",
      "tensor(1.5934, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-eb1ad440bb6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "EPOCH = 1\n",
    "\n",
    "batch_loader.initialize_batch()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    batch_loader.initialize_batch()\n",
    "    while batch_loader.end_flag == False:\n",
    "        optimizer.zero_grad()\n",
    "        input_tensor, loss_mask = batch_loader.get_batch()\n",
    "        \n",
    "        input_tensor_tier = split_tier(input_tensor)\n",
    "        loss_mask_tier = split_tier(loss_mask)\n",
    "        \n",
    "        tier_1 = input_tensor_tier[0]\n",
    "        \n",
    "        input_tensor = tier_1.view([tier_1.shape[0], tier_1.shape[1], tier_1.shape[2], 1])\n",
    "        \n",
    "        loss = net(input_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
